{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting Started with OpenHands SDK\n",
        "\n",
        "This notebook is an introduction to building agents with the [OpenHands SDK](https://docs.openhands.dev/sdk).\n",
        "\n",
        "**What you'll learn:**\n",
        "1. How to create an LLM and Agent\n",
        "2. How to use built-in tools (Terminal, FileEditor, TaskTracker)\n",
        "3. **MCP integration** - Add Tavily search with just config (no code!)\n",
        "4. **Built-in persistence** - Auto-save & resume with 2 parameters\n",
        "\n",
        "**Why OpenHands SDK?**\n",
        "- **MCP built-in** - Connect to any MCP server with config, not code\n",
        "- **Persistence built-in** - No graph setup, no external DB, just 2 params\n",
        "- Production-ready with type safety (Pydantic)\n",
        "- Built-in tools for coding tasks\n",
        "- Works with any LLM (OpenAI, Anthropic, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note: Tavily MCP requires Node.js (for npx command)\n",
        "!pip install openhands-sdk python-dotenv -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load Environment\n",
        "\n",
        "Create a `.env` file:\n",
        "```\n",
        "LLM_API_KEY=sk-your-openai-key\n",
        "LLM_MODEL=openai/gpt-5\n",
        "TAVILY_API_KEY=tvly-your-tavily-key\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "print(f\"Model: {os.getenv('LLM_MODEL', 'openai/gpt-5')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openhands.sdk import LLM\n",
        "\n",
        "llm = LLM(\n",
        "    model=\"openai/gpt-5\",\n",
        "    api_key=os.getenv(\"LLM_API_KEY\"),\n",
        "    base_url=os.getenv(\"LLM_BASE_URL\", None),\n",
        ")\n",
        "\n",
        "print(f\"✓ LLM ready: {llm.model}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Configure MCP Server (Tavily)\n",
        "\n",
        "[Model Context Protocol (MCP)](https://modelcontextprotocol.io/) lets you add tools via config instead of code.\n",
        "\n",
        "OpenHands SDK has **built-in MCP support** - just pass a config dict to your Agent!\n",
        "\n",
        "We'll use the [Tavily MCP Server](https://docs.tavily.com/documentation/mcp) which provides:\n",
        "- `tavily-search` - Web search with citations\n",
        "- `tavily-extract` - Extract content from URLs\n",
        "\n",
        "**Requires:** Node.js installed (for `npx`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MCP config - that's it! No custom classes needed.\n",
        "# Compare this to ~40 lines of Action/Observation/Executor code!\n",
        "\n",
        "mcp_config = {\n",
        "    \"mcpServers\": {\n",
        "        \"tavily\": {\n",
        "            \"command\": \"npx\",\n",
        "            \"args\": [\"-y\", \"tavily-mcp@0.1.3\"],\n",
        "            \"env\": {\"TAVILY_API_KEY\": os.getenv(\"TAVILY_API_KEY\")}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"✓ MCP config ready (Tavily search + extract)\")\n",
        "print(\"  Tools will be: tavily-search, tavily-extract\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Create the Agent with MCP Tools\n",
        "\n",
        "Pass `mcp_config` to the Agent - MCP tools are automatically discovered and added!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openhands.sdk import Agent, Tool\n",
        "from openhands.tools.terminal import TerminalTool\n",
        "from openhands.tools.file_editor import FileEditorTool\n",
        "from openhands.tools.task_tracker import TaskTrackerTool\n",
        "\n",
        "agent = Agent(\n",
        "    llm=llm,\n",
        "    tools=[\n",
        "        Tool(name=TerminalTool.name),\n",
        "        Tool(name=FileEditorTool.name),\n",
        "        Tool(name=TaskTrackerTool.name),\n",
        "        # Tavily tools come from MCP - no Tool() entry needed!\n",
        "    ],\n",
        "    mcp_config=mcp_config,  # MCP tools auto-discovered\n",
        ")\n",
        "\n",
        "print(\"✓ Agent ready\")\n",
        "print(f\"  Built-in tools: {[t.name for t in agent.tools]}\")\n",
        "print(f\"  MCP tools: tavily-search, tavily-extract (from Tavily MCP server)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Create a Conversation with Persistence\n",
        "\n",
        "OpenHands SDK has **built-in persistence** - just add 2 parameters:\n",
        "- `persistence_dir`: Where to save (auto-creates directory)\n",
        "- `conversation_id`: Unique session ID (use same ID to resume)\n",
        "\n",
        "**Every event is auto-saved.** If interrupted, re-run with same ID to resume from exact point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openhands.sdk import Conversation\n",
        "import uuid\n",
        "\n",
        "cwd = os.getcwd()\n",
        "\n",
        "# Create a deterministic UUID from a name (so you can resume with same ID)\n",
        "SESSION_NAME = \"simple-agent-demo\"\n",
        "conversation_id = uuid.uuid5(uuid.NAMESPACE_DNS, SESSION_NAME)\n",
        "\n",
        "# Built-in persistence: just 2 parameters!\n",
        "# Compare to LangGraph which requires: StateGraph, nodes, edges, checkpointer class\n",
        "conversation = Conversation(\n",
        "    agent=agent,\n",
        "    workspace=cwd,\n",
        "    persistence_dir=\"./.conversations\",     # Where to save state\n",
        "    conversation_id=conversation_id,        # UUID (use same name to resume)\n",
        ")\n",
        "\n",
        "print(f\"✓ Conversation ready in: {cwd}\")\n",
        "print(f\"✓ Persistence: ./.conversations/{conversation_id.hex}/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Run a Research Query (uses Tavily search!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ask the agent to research something - it will use tavily-search from MCP\n",
        "conversation.send_message(\"\"\"\n",
        "Estimate the main profit drivers for NVIDIA in 2026.\n",
        "Use web search to find current information, then summarize your findings.\n",
        "\"\"\")\n",
        "conversation.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OpenHands SDK Advantages\n",
        "\n",
        "### 1. MCP Integration (No Code!)\n",
        "\n",
        "We added Tavily search with just a config dict - no custom classes:\n",
        "\n",
        "```python\n",
        "# OpenHands SDK: 10 lines of config\n",
        "mcp_config = {\n",
        "    \"mcpServers\": {\n",
        "        \"tavily\": {\"command\": \"npx\", \"args\": [\"-y\", \"tavily-mcp\"], ...}\n",
        "    }\n",
        "}\n",
        "agent = Agent(llm=llm, mcp_config=mcp_config)\n",
        "```\n",
        "\n",
        "vs. Custom tool approach (~40 lines): See `01_deep_research.ipynb` for the Action/Observation/Executor pattern when you need full control.\n",
        "\n",
        "### 2. Built-in Persistence\n",
        "\n",
        "Your conversation is saved to `.conversations/<uuid>/`. Resume anytime:\n",
        "\n",
        "```python\n",
        "import uuid\n",
        "# Same name = same UUID = auto-restore\n",
        "conversation_id = uuid.uuid5(uuid.NAMESPACE_DNS, \"simple-agent-demo\")\n",
        "conversation = Conversation(\n",
        "    agent=agent,\n",
        "    persistence_dir=\"./.conversations\",\n",
        "    conversation_id=conversation_id,\n",
        ")\n",
        "conversation.run()  # Continues where it left off\n",
        "```\n",
        "\n",
        "### Compare to LangGraph\n",
        "\n",
        "| Feature | OpenHands SDK | LangGraph |\n",
        "|---------|---------------|-----------|\n",
        "| **Add tools** | Config dict (MCP) | Code or MCP |\n",
        "| **Persistence** | 2 params | Graph + checkpointer class |\n",
        "| **Graph required?** | ❌ No | ✅ Yes |\n",
        "| **Lines for basic agent** | ~15 | ~40-50 |\n",
        "\n",
        "**OpenHands SDK: MCP + Persistence without the graph overhead.**\n",
        "\n",
        "---\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- `01_deep_research.ipynb` - Multi-agent workflow with custom tools\n",
        "- `02_parallel_research.ipynb` - Parallel sub-agent delegation"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
