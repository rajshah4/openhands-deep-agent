{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deep Research Agent with OpenHands SDK\n",
        "\n",
        "This notebook demonstrates a **3-phase deep research workflow**:\n",
        "\n",
        "| Phase | Agent | Output |\n",
        "|-------|-------|--------|\n",
        "| **1. Planning** | GPT-4o creates plan â†’ GPT-5.1 critiques â†’ iterate until approved | `research_plan.md` |\n",
        "| **2. Research** | GPT-4o executes searches, gathers raw findings | Updated `research_plan.md` |\n",
        "| **3. Synthesis** | GPT-5.1 synthesizes all findings into comprehensive report | `research_report.md` |\n",
        "\n",
        "**Features:**\n",
        "- âœ… Multi-agent collaboration (GPT-4o + GPT-5.1)\n",
        "- âœ… Iterative plan refinement with scoring\n",
        "- âœ… **Checkpointing** - Resume from crash/interrupt\n",
        "- âœ… **Observability** - Laminar tracing (set `LMNR_PROJECT_API_KEY`)\n",
        "- âœ… Professional report synthesis with citations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup (same as notebook 00)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install openhands-sdk python-dotenv tavily-python -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "from typing import List\n",
        "from pydantic import Field\n",
        "from tavily import TavilyClient\n",
        "from openhands.sdk import LLM, Agent, Conversation, Tool, Action, Observation, ToolDefinition, TextContent\n",
        "from openhands.sdk.tool import register_tool, ToolExecutor\n",
        "from openhands.tools.terminal import TerminalTool\n",
        "from openhands.tools.file_editor import FileEditorTool\n",
        "from openhands.tools.task_tracker import TaskTrackerTool\n",
        "\n",
        "print(f\"Model: {os.getenv('LLM_MODEL', 'openai/gpt-4o')}\")\n",
        "\n",
        "# Observability: auto-enabled if LMNR_PROJECT_API_KEY is set\n",
        "if os.getenv(\"LMNR_PROJECT_API_KEY\"):\n",
        "    print(\"âœ“ Observability: Laminar tracing enabled (view at laminar.sh)\")\n",
        "else:\n",
        "    print(\"â„¹ Observability: Set LMNR_PROJECT_API_KEY for tracing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create LLM and Tavily Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create LLM\n",
        "llm = LLM(\n",
        "    model=\"openai/gpt-4o\",\n",
        "    api_key=os.getenv(\"LLM_API_KEY\"),\n",
        "    base_url=os.getenv(\"LLM_BASE_URL\", None),\n",
        ")\n",
        "\n",
        "# Create Tavily client and tool (same as notebook 00)\n",
        "tavily = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
        "\n",
        "class SearchAction(Action):\n",
        "    query: str = Field(description=\"Search query\")\n",
        "\n",
        "class SearchObservation(Observation):\n",
        "    results: str = Field(description=\"Results\")\n",
        "    @property\n",
        "    def to_llm_content(self): return [TextContent(text=self.results)]\n",
        "\n",
        "class SearchExecutor(ToolExecutor):\n",
        "    def __call__(self, action: SearchAction, conversation=None) -> SearchObservation:\n",
        "        try:\n",
        "            r = tavily.search(query=action.query, max_results=5)\n",
        "            text = \"\\n\\n\".join([\n",
        "                f\"**{x['title']}**\\n{x['content'][:300]}\\nSource: {x['url']}\"\n",
        "                for x in r['results']\n",
        "            ])\n",
        "            return SearchObservation(results=text or \"No results found\")\n",
        "        except Exception as e:\n",
        "            # Error recovery: return error message instead of crashing\n",
        "            return SearchObservation(results=f\"Search failed: {str(e)}. Try a different query.\")\n",
        "\n",
        "class SearchTool(ToolDefinition[SearchAction, SearchObservation]):\n",
        "    @classmethod\n",
        "    def create(cls, conv_state) -> List[\"SearchTool\"]:\n",
        "        return [cls(description=\"Web search via Tavily (returns results with citations)\",\n",
        "                    action_type=SearchAction, observation_type=SearchObservation, \n",
        "                    executor=SearchExecutor())]\n",
        "\n",
        "register_tool(\"TavilySearch\", SearchTool.create)\n",
        "print(\"âœ“ LLM and Tavily tool ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create Agent with File Editor\n",
        "\n",
        "The key difference from notebook 00: we include `FileEditorTool` so the agent can **create and update the research plan file**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent = Agent(\n",
        "    llm=llm,\n",
        "    tools=[\n",
        "        Tool(name=FileEditorTool.name),     # Read/write research_plan.md\n",
        "        Tool(name=TaskTrackerTool.name),    # Track task completion\n",
        "        Tool(name=\"TavilySearch\"),          # Web search with citations\n",
        "    ],\n",
        ")\n",
        "print(\"âœ“ Agent ready with tools:\", [t.name for t in agent.tools])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: The Deep Research Prompt\n",
        "\n",
        "This is where the magic happens. We give the agent explicit instructions to:\n",
        "1. **Create a plan file** before starting research\n",
        "2. **Update the plan** as each task completes\n",
        "3. **Iterate and refine** if initial searches don't yield enough info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DEEP_RESEARCH_PROMPT = \"\"\"\n",
        "You are a deep research agent. Your task is to thoroughly research a topic using a structured, iterative approach.\n",
        "\n",
        "## Your Process:\n",
        "\n",
        "### Phase 1: Planning\n",
        "1. Create a file called `research_plan.md` with:\n",
        "   - The main research question\n",
        "   - 3-5 specific sub-questions to investigate\n",
        "   - A checklist of tasks (use markdown checkboxes: `- [ ]` and `- [x]`)\n",
        "\n",
        "### Phase 2: Research\n",
        "For each sub-question:\n",
        "1. Read `research_plan.md` to check what's done and what's next\n",
        "2. Use TavilySearch to find relevant information\n",
        "3. Take notes on key findings (you can add them to the plan file)\n",
        "4. Mark the task as complete in `research_plan.md` (change `- [ ]` to `- [x]`)\n",
        "\n",
        "### Phase 3: Refinement\n",
        "After initial research:\n",
        "1. Review all findings\n",
        "2. Identify any gaps or areas needing more depth\n",
        "3. Add new tasks to `research_plan.md` if needed\n",
        "4. Continue researching until satisfied\n",
        "\n",
        "### Phase 4: Synthesis\n",
        "1. Read the final `research_plan.md` \n",
        "2. Create a comprehensive summary with:\n",
        "   - Key findings organized by theme\n",
        "   - Important sources (URLs)\n",
        "   - Conclusions and implications\n",
        "\n",
        "## Rules:\n",
        "- ALWAYS create and update `research_plan.md` - this is your memory\n",
        "- ALWAYS include source URLs in your findings (citations)\n",
        "- If a search fails, try rephrasing the query\n",
        "- Be thorough but efficient - don't repeat searches\n",
        "\n",
        "Now research: {topic}\n",
        "\"\"\"\n",
        "\n",
        "print(\"âœ“ Deep research prompt ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Create Critique Agent (GPT-5.1)\n",
        "\n",
        "Following the [OpenHands iterative refinement pattern](https://docs.openhands.dev/sdk/guides/iterative-refinement), we use a second model to critique and improve the research plan before execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a separate LLM for critique (GPT-5.1 for stronger reasoning)\n",
        "critique_llm = LLM(\n",
        "    model=\"openai/gpt-5.1\",\n",
        "    api_key=os.getenv(\"LLM_API_KEY\"),\n",
        "    base_url=os.getenv(\"LLM_BASE_URL\", None),\n",
        ")\n",
        "\n",
        "# Critique agent only needs file access (no search needed)\n",
        "critique_agent = Agent(\n",
        "    llm=critique_llm,\n",
        "    tools=[\n",
        "        Tool(name=FileEditorTool.name),  # Read/write plan and critique files\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(f\"âœ“ Critique agent ready (model: {critique_llm.model})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Run the Research Pipeline\n",
        "\n",
        "The workflow with **checkpointing for resume capability**:\n",
        "\n",
        "1. **Phase 1 - Planning**: Create plan â†’ Critique â†’ Improve â†’ Loop\n",
        "2. **Phase 2 - Research**: Execute Tavily searches for each sub-question\n",
        "3. **Phase 3 - Synthesis**: GPT-5.1 writes comprehensive report\n",
        "\n",
        "ğŸ’¾ **Checkpointing**: Progress is saved to `checkpoint.json` after each phase. If the notebook crashes or is interrupted, re-run this cell to resume from where you left off."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Configuration\n",
        "QUALITY_THRESHOLD = 80.0\n",
        "MAX_ITERATIONS = 2\n",
        "cwd = os.getcwd()\n",
        "CHECKPOINT_FILE = \"checkpoint.json\"\n",
        "\n",
        "# Choose your research topic\n",
        "topic = \"What are the latest breakthroughs in AI agents and autonomous systems in 2024-2025?\"\n",
        "\n",
        "# ===========================================\n",
        "# Checkpoint System for Resume Capability\n",
        "# ===========================================\n",
        "\n",
        "def save_checkpoint(phase: str, iteration: int = 0):\n",
        "    \"\"\"Save current progress to enable resume after crash/interrupt.\"\"\"\n",
        "    checkpoint = {\n",
        "        \"phase\": phase,\n",
        "        \"iteration\": iteration,\n",
        "        \"topic\": topic,\n",
        "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    }\n",
        "    with open(CHECKPOINT_FILE, \"w\") as f:\n",
        "        json.dump(checkpoint, f, indent=2)\n",
        "    print(f\"  ğŸ’¾ Checkpoint saved: {phase}\")\n",
        "\n",
        "def load_checkpoint():\n",
        "    \"\"\"Load checkpoint if exists.\"\"\"\n",
        "    try:\n",
        "        with open(CHECKPOINT_FILE, \"r\") as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        return None\n",
        "\n",
        "def clear_checkpoint():\n",
        "    \"\"\"Remove checkpoint after successful completion.\"\"\"\n",
        "    if os.path.exists(CHECKPOINT_FILE):\n",
        "        os.remove(CHECKPOINT_FILE)\n",
        "\n",
        "# Check for existing checkpoint\n",
        "checkpoint = load_checkpoint()\n",
        "if checkpoint:\n",
        "    print(f\"ğŸ”„ Found checkpoint from {checkpoint['timestamp']}\")\n",
        "    print(f\"   Phase: {checkpoint['phase']}, Iteration: {checkpoint.get('iteration', 0)}\")\n",
        "    print(f\"   Topic: {checkpoint['topic'][:50]}...\")\n",
        "    resume_from = checkpoint['phase']\n",
        "else:\n",
        "    resume_from = None\n",
        "    print(\"ğŸ“ Starting fresh research (no checkpoint found)\")\n",
        "\n",
        "# Prompts\n",
        "PLAN_CREATION_PROMPT = \"\"\"\n",
        "Create a research plan in `research_plan.md` for the topic: {topic}\n",
        "\n",
        "The plan should include:\n",
        "1. Main research question\n",
        "2. 4-5 specific sub-questions to investigate\n",
        "3. A checklist of search tasks (use `- [ ]` format)\n",
        "\n",
        "Just create the plan file - don't execute any searches yet.\n",
        "\"\"\"\n",
        "\n",
        "CRITIQUE_PROMPT = \"\"\"\n",
        "Read `research_plan.md` and evaluate the research plan quality.\n",
        "\n",
        "Score each dimension (0-25 points):\n",
        "1. **Comprehensiveness**: Do sub-questions cover all important aspects?\n",
        "2. **Specificity**: Are questions concrete enough to search effectively?\n",
        "3. **Diversity**: Do questions explore different angles/perspectives?\n",
        "4. **Structure**: Is the plan logically organized?\n",
        "\n",
        "Write your evaluation to `critique.md` with:\n",
        "- Scores for each dimension\n",
        "- Specific suggestions for improvement\n",
        "- Final line MUST be: `SCORE: XX/100`\n",
        "\"\"\"\n",
        "\n",
        "IMPROVE_PROMPT = \"\"\"\n",
        "Read `critique.md` and improve `research_plan.md` based on the feedback.\n",
        "Address each suggestion while keeping the good parts of the original plan.\n",
        "\"\"\"\n",
        "\n",
        "def parse_score(filepath):\n",
        "    \"\"\"Extract score from critique file.\"\"\"\n",
        "    try:\n",
        "        with open(filepath, \"r\") as f:\n",
        "            content = f.read()\n",
        "        match = re.search(r\"SCORE:\\s*(\\d+)\", content, re.IGNORECASE)\n",
        "        return float(match.group(1)) if match else 0.0\n",
        "    except FileNotFoundError:\n",
        "        return 0.0\n",
        "\n",
        "# ===========================================\n",
        "# PHASE 1: Planning (with iterative critique)\n",
        "# ===========================================\n",
        "\n",
        "research_conversation = Conversation(agent=agent, workspace=cwd)\n",
        "\n",
        "if resume_from in [None, \"planning\"]:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"PHASE 1: Creating initial research plan...\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    research_conversation.send_message(PLAN_CREATION_PROMPT.format(topic=topic))\n",
        "    research_conversation.run()\n",
        "    save_checkpoint(\"planning\", iteration=0)\n",
        "    \n",
        "    # Iterative refinement loop\n",
        "    start_iteration = checkpoint.get('iteration', 0) if resume_from == \"planning\" else 0\n",
        "    for iteration in range(start_iteration, MAX_ITERATIONS):\n",
        "        print(f\"\\n{'=' * 60}\")\n",
        "        print(f\"ITERATION {iteration + 1}: Critique agent evaluating plan...\")\n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "        critique_conversation = Conversation(agent=critique_agent, workspace=cwd)\n",
        "        critique_conversation.send_message(CRITIQUE_PROMPT)\n",
        "        critique_conversation.run()\n",
        "        \n",
        "        score = parse_score(\"critique.md\")\n",
        "        print(f\"\\nâ†’ Plan quality score: {score}/100\")\n",
        "        \n",
        "        if score >= QUALITY_THRESHOLD:\n",
        "            print(f\"âœ“ Plan approved! (threshold: {QUALITY_THRESHOLD})\")\n",
        "            break\n",
        "        else:\n",
        "            print(f\"âœ— Below threshold ({QUALITY_THRESHOLD}). Improving...\")\n",
        "            research_conversation.send_message(IMPROVE_PROMPT)\n",
        "            research_conversation.run()\n",
        "            save_checkpoint(\"planning\", iteration=iteration+1)\n",
        "else:\n",
        "    print(\"â­ï¸  Skipping Phase 1 (already complete)\")\n",
        "\n",
        "# ===========================================\n",
        "# PHASE 2: Research (execute searches)\n",
        "# ===========================================\n",
        "\n",
        "if resume_from in [None, \"planning\", \"research\"]:\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(\"PHASE 2: Executing research plan...\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    EXECUTE_PROMPT = \"\"\"\n",
        "    Read `research_plan.md` and execute each task:\n",
        "\n",
        "    1. For each unchecked task (`- [ ]`):\n",
        "       - Use TavilySearch to find information\n",
        "       - Add the RAW findings (with source URLs) under each task\n",
        "       - Mark the task complete (`- [x]`)\n",
        "\n",
        "    Keep all findings in `research_plan.md` - this is your research notes.\n",
        "    Do NOT write a summary yet - just gather all the information.\n",
        "    \"\"\"\n",
        "    \n",
        "    research_conversation.send_message(EXECUTE_PROMPT)\n",
        "    research_conversation.run()\n",
        "    save_checkpoint(\"research\")\n",
        "    \n",
        "    print(\"\\nâœ“ Research gathering complete!\")\n",
        "else:\n",
        "    print(\"â­ï¸  Skipping Phase 2 (already complete)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===========================================\n",
        "# PHASE 3: Synthesis (comprehensive report)\n",
        "# ===========================================\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(\"PHASE 3: Synthesizing comprehensive report (GPT-5.1)...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "SYNTHESIS_PROMPT = \"\"\"\n",
        "You are a research synthesis expert. Read `research_plan.md` which contains:\n",
        "- The original research question\n",
        "- Sub-questions that were investigated\n",
        "- Raw findings from web searches with source URLs\n",
        "\n",
        "Your task: Write a comprehensive research report to `research_report.md`\n",
        "\n",
        "## Report Structure:\n",
        "\n",
        "# [Research Topic Title]\n",
        "\n",
        "## Executive Summary\n",
        "(2-3 paragraph overview of key findings and conclusions)\n",
        "\n",
        "## 1. Introduction\n",
        "(Context, why this topic matters, scope of research)\n",
        "\n",
        "## 2. Key Findings\n",
        "\n",
        "### 2.1 [Theme 1 from the research]\n",
        "(Synthesize related findings into coherent paragraphs, not bullet points)\n",
        "(Cite sources inline like: \"According to [Source Name](url)...\")\n",
        "\n",
        "### 2.2 [Theme 2]\n",
        "(Continue for each major theme discovered)\n",
        "\n",
        "### 2.3 [Theme 3]\n",
        "...\n",
        "\n",
        "## 3. Analysis & Implications\n",
        "(What do these findings mean? Trends, patterns, implications for the future)\n",
        "\n",
        "## 4. Limitations\n",
        "(What wasn't covered? What uncertainties remain?)\n",
        "\n",
        "## 5. Conclusion\n",
        "(Final synthesis and key takeaways)\n",
        "\n",
        "## References\n",
        "(List all sources with URLs)\n",
        "\n",
        "---\n",
        "\n",
        "IMPORTANT:\n",
        "- Write in a professional, analytical tone\n",
        "- Synthesize and connect ideas - don't just list facts\n",
        "- Every claim should reference a source\n",
        "- Be comprehensive but concise\n",
        "- Make it feel like a real research report, not a summary of search results\n",
        "\"\"\"\n",
        "\n",
        "# Use the critique agent (GPT-5.1) for synthesis - it has stronger reasoning\n",
        "synthesis_conversation = Conversation(agent=critique_agent, workspace=cwd)\n",
        "synthesis_conversation.send_message(SYNTHESIS_PROMPT)\n",
        "synthesis_conversation.run()\n",
        "\n",
        "# Clear checkpoint on successful completion\n",
        "clear_checkpoint()\n",
        "print(\"\\nâœ“ Research report complete!\")\n",
        "print(\"âœ“ Checkpoint cleared (research finished successfully)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: View the Comprehensive Research Report\n",
        "\n",
        "GPT-5.1 synthesized all findings into a professional `research_report.md`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Show the comprehensive research report (synthesized by GPT-5.1)\n",
        "try:\n",
        "    with open(\"research_report.md\", \"r\") as f:\n",
        "        display(Markdown(f.read()))\n",
        "except FileNotFoundError:\n",
        "    print(\"research_report.md not found - run the cells above first\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Architecture Summary\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  PHASE 1: PLANNING (with iterative critique)                â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚  GPT-4o creates plan â†’ GPT-5.1 critiques â†’ improve â†’ loop   â”‚\n",
        "â”‚  Output: research_plan.md (approved sub-questions)          â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                              â†“\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  PHASE 2: RESEARCH (gather raw findings)                    â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚  GPT-4o executes Tavily searches for each sub-question      â”‚\n",
        "â”‚  Output: research_plan.md (with raw findings + URLs)        â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                              â†“\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  PHASE 3: SYNTHESIS (comprehensive report)                  â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚  GPT-5.1 reads all findings and writes professional report  â”‚\n",
        "â”‚  Output: research_report.md (executive summary, analysis,   â”‚\n",
        "â”‚          themed sections, implications, citations)          â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "### Why Two Models?\n",
        "\n",
        "| Model | Role | Why |\n",
        "|-------|------|-----|\n",
        "| GPT-4o | Research Agent | Fast, good at tool use, searches |\n",
        "| GPT-5.1 | Critique + Synthesis | Stronger reasoning, better writing |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OpenHands SDK Features Used\n",
        "\n",
        "| Feature | How It's Used |\n",
        "|---------|--------------|\n",
        "| **Multi-Agent** | GPT-4o (research) + GPT-5.1 (critique & synthesis) |\n",
        "| **Iterative Refinement** | Plan critiqued and improved until threshold met |\n",
        "| **File-based State** | `research_plan.md` â†’ `research_report.md` pipeline |\n",
        "| **Checkpointing** | Resume from crash via `checkpoint.json` |\n",
        "| **Observability** | Laminar tracing for debugging (set `LMNR_PROJECT_API_KEY`) |\n",
        "\n",
        "### Output Files\n",
        "\n",
        "| File | Purpose |\n",
        "|------|---------|\n",
        "| `research_plan.md` | Working document with sub-questions + raw findings |\n",
        "| `critique.md` | Plan evaluation feedback (debugging) |\n",
        "| `research_report.md` | **Final deliverable** - comprehensive report |\n",
        "| `checkpoint.json` | Resume state (auto-deleted on success) |"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
