{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Deep Research Agent with OpenHands SDK\n",
    "\n",
    "This notebook demonstrates how to build a deep research agent using the OpenHands SDK. The agent incorporates state-of-the-art patterns including:\n",
    "\n",
    "- **Task Decomposition**: Breaking down research topics into manageable subtasks\n",
    "- **Web Search Integration**: Using Tavily MCP for structured web search\n",
    "- **Synthesis with Citations**: Combining findings into coherent reports\n",
    "- **Structured Outputs**: Using Pydantic for validated data structures\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                    CONTROLLER/ORCHESTRATOR                       ‚îÇ\n",
    "‚îÇ              (Main agent with orchestration loop)                ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                      ‚îÇ\n",
    "        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "        ‚ñº             ‚ñº             ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   PLANNER     ‚îÇ ‚îÇ   SEARCHER    ‚îÇ ‚îÇ  SYNTHESIZER  ‚îÇ\n",
    "‚îÇ   AGENT       ‚îÇ ‚îÇ   AGENT       ‚îÇ ‚îÇ    AGENT      ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ ‚Ä¢ Decompose   ‚îÇ ‚îÇ ‚Ä¢ Web search  ‚îÇ ‚îÇ ‚Ä¢ Aggregate   ‚îÇ\n",
    "‚îÇ   research    ‚îÇ ‚îÇ   (Tavily API)‚îÇ ‚îÇ   findings    ‚îÇ\n",
    "‚îÇ ‚Ä¢ Task list   ‚îÇ ‚îÇ ‚Ä¢ Structured  ‚îÇ ‚îÇ ‚Ä¢ Citations   ‚îÇ\n",
    "‚îÇ ‚Ä¢ Priorities  ‚îÇ ‚îÇ   snippets    ‚îÇ ‚îÇ ‚Ä¢ Synthesis   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install OpenHands SDK and dependencies\n",
    "!pip install openhands-sdk openhands-tools\n",
    "\n",
    "# Install Tavily Python client for web search\n",
    "!pip install tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Configuration\n",
    "\n",
    "Set up your API keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Set LLM API key (Anthropic, OpenAI, or OpenHands Cloud)\n",
    "if not os.getenv(\"LLM_API_KEY\"):\n",
    "    os.environ[\"LLM_API_KEY\"] = getpass(\"Enter your LLM API key: \")\n",
    "\n",
    "# Set Tavily API key for web search\n",
    "if not os.getenv(\"TAVILY_API_KEY\"):\n",
    "    os.environ[\"TAVILY_API_KEY\"] = getpass(\"Enter your Tavily API key: \")\n",
    "\n",
    "# Configure model (adjust based on your provider)\n",
    "os.environ[\"LLM_MODEL\"] = os.getenv(\"LLM_MODEL\", \"anthropic/claude-sonnet-4-5-20250929\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field, SecretStr\n",
    "\n",
    "from openhands.sdk import (\n",
    "    LLM,\n",
    "    Agent,\n",
    "    Conversation,\n",
    "    Tool,\n",
    "    Action,\n",
    "    Observation,\n",
    "    ToolDefinition,\n",
    "    ToolExecutor,\n",
    "    TextContent,\n",
    "    get_logger,\n",
    ")\n",
    "from openhands.sdk.tool import register_tool\n",
    "from openhands.tools.file_editor import FileEditorTool\n",
    "from openhands.tools.terminal import TerminalTool\n",
    "from openhands.tools.task_tracker import TaskTrackerTool\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Structured Data Models\n",
    "\n",
    "Using Pydantic for type-safe, validated data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research task structure\n",
    "class ResearchTask(BaseModel):\n",
    "    \"\"\"A single research subtask\"\"\"\n",
    "    id: str = Field(description=\"Unique task identifier\")\n",
    "    title: str = Field(description=\"Brief task title\")\n",
    "    description: str = Field(description=\"Detailed task description\")\n",
    "    priority: int = Field(description=\"Priority level (1-5, 5 being highest)\")\n",
    "    status: str = Field(default=\"todo\", description=\"Task status: todo, in_progress, done\")\n",
    "    dependencies: List[str] = Field(default_factory=list, description=\"IDs of tasks this depends on\")\n",
    "\n",
    "# Research plan structure\n",
    "class ResearchPlan(BaseModel):\n",
    "    \"\"\"Complete research plan with decomposed tasks\"\"\"\n",
    "    topic: str = Field(description=\"Main research topic\")\n",
    "    objective: str = Field(description=\"Research objective\")\n",
    "    tasks: List[ResearchTask] = Field(description=\"List of research tasks\")\n",
    "    created_at: datetime = Field(default_factory=datetime.now)\n",
    "\n",
    "# Search result structure\n",
    "class SearchResult(BaseModel):\n",
    "    \"\"\"Structured search result\"\"\"\n",
    "    title: str = Field(description=\"Result title\")\n",
    "    url: str = Field(description=\"Source URL\")\n",
    "    snippet: str = Field(description=\"Content snippet\")\n",
    "    relevance_score: float = Field(description=\"Relevance score (0-1)\")\n",
    "    \n",
    "# Research finding structure\n",
    "class ResearchFinding(BaseModel):\n",
    "    \"\"\"A synthesized research finding\"\"\"\n",
    "    key_point: str = Field(description=\"Main finding or insight\")\n",
    "    evidence: List[str] = Field(description=\"Supporting evidence\")\n",
    "    sources: List[str] = Field(description=\"Source URLs\")\n",
    "    confidence: float = Field(description=\"Confidence level (0-1)\")\n",
    "\n",
    "# Final research report structure\n",
    "class ResearchReport(BaseModel):\n",
    "    \"\"\"Complete research report\"\"\"\n",
    "    topic: str = Field(description=\"Research topic\")\n",
    "    executive_summary: str = Field(description=\"Executive summary\")\n",
    "    findings: List[ResearchFinding] = Field(description=\"Key findings\")\n",
    "    methodology: str = Field(description=\"Research methodology\")\n",
    "    limitations: List[str] = Field(description=\"Research limitations\")\n",
    "    recommendations: List[str] = Field(description=\"Recommendations for further research\")\n",
    "    created_at: datetime = Field(default_factory=datetime.now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Custom Tools for Research Workflow\n",
    "\n",
    "### 1. Research Planner Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planner Tool - Decomposes research topics into structured tasks\n",
    "class PlannerAction(Action):\n",
    "    \"\"\"Action to create a research plan\"\"\"\n",
    "    topic: str = Field(description=\"Research topic to plan\")\n",
    "    depth: str = Field(\n",
    "        default=\"moderate\", \n",
    "        description=\"Research depth: quick, moderate, or deep\"\n",
    "    )\n",
    "\n",
    "class PlannerObservation(Observation):\n",
    "    \"\"\"Observation containing the research plan\"\"\"\n",
    "    plan: ResearchPlan = Field(description=\"Generated research plan\")\n",
    "    \n",
    "    @property\n",
    "    def to_llm_content(self):\n",
    "        tasks_summary = \"\\n\".join([\n",
    "            f\"  {i+1}. [{t.priority}] {t.title}: {t.description[:100]}...\"\n",
    "            for i, t in enumerate(self.plan.tasks[:5])\n",
    "        ])\n",
    "        return [TextContent(text=f\"\"\"\n",
    "Research Plan Created:\n",
    "Topic: {self.plan.topic}\n",
    "Objective: {self.plan.objective}\n",
    "Number of tasks: {len(self.plan.tasks)}\n",
    "\n",
    "Top tasks:\n",
    "{tasks_summary}\n",
    "\"\"\")]\n",
    "\n",
    "class PlannerExecutor(ToolExecutor[PlannerAction, PlannerObservation]):\n",
    "    \"\"\"Executor that creates research plans\"\"\"\n",
    "    \n",
    "    def __init__(self, llm: LLM):\n",
    "        self.llm = llm\n",
    "    \n",
    "    def __call__(self, action: PlannerAction, conversation=None) -> PlannerObservation:\n",
    "        # Use LLM to decompose the research topic\n",
    "        prompt = f\"\"\"\n",
    "Create a detailed research plan for the topic: \"{action.topic}\"\n",
    "Research depth: {action.depth}\n",
    "\n",
    "Break this down into 5-8 specific, actionable research tasks.\n",
    "Each task should have:\n",
    "- A unique ID (e.g., task_1, task_2)\n",
    "- Clear title and description\n",
    "- Priority (1-5)\n",
    "- Any dependencies on other tasks\n",
    "\n",
    "Output the plan as a JSON object matching this structure:\n",
    "{{\n",
    "  \"topic\": \"...\",\n",
    "  \"objective\": \"...\",\n",
    "  \"tasks\": [\n",
    "    {{\n",
    "      \"id\": \"task_1\",\n",
    "      \"title\": \"...\",\n",
    "      \"description\": \"...\",\n",
    "      \"priority\": 5,\n",
    "      \"dependencies\": []\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.llm.completion(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        # Parse the response\n",
    "        try:\n",
    "            plan_data = json.loads(response.choices[0].message.content)\n",
    "            plan = ResearchPlan(**plan_data)\n",
    "        except Exception as e:\n",
    "            # Fallback plan if parsing fails\n",
    "            logger.error(f\"Failed to parse plan: {e}\")\n",
    "            plan = ResearchPlan(\n",
    "                topic=action.topic,\n",
    "                objective=f\"Research {action.topic} comprehensively\",\n",
    "                tasks=[\n",
    "                    ResearchTask(\n",
    "                        id=\"task_1\",\n",
    "                        title=\"Initial exploration\",\n",
    "                        description=f\"Explore basic concepts and definitions related to {action.topic}\",\n",
    "                        priority=5\n",
    "                    ),\n",
    "                    ResearchTask(\n",
    "                        id=\"task_2\",\n",
    "                        title=\"Deep dive research\",\n",
    "                        description=f\"Research current state and recent developments in {action.topic}\",\n",
    "                        priority=4,\n",
    "                        dependencies=[\"task_1\"]\n",
    "                    ),\n",
    "                    ResearchTask(\n",
    "                        id=\"task_3\",\n",
    "                        title=\"Synthesis and analysis\",\n",
    "                        description=\"Synthesize findings and identify key insights\",\n",
    "                        priority=3,\n",
    "                        dependencies=[\"task_1\", \"task_2\"]\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        return PlannerObservation(plan=plan)\n",
    "\n",
    "# Tool definition\n",
    "PLANNER_DESCRIPTION = \"\"\"\n",
    "Research planning tool that decomposes complex research topics into structured tasks.\n",
    "- Creates prioritized task lists with dependencies\n",
    "- Supports different research depths (quick/moderate/deep)\n",
    "- Outputs structured research plans\n",
    "\"\"\"\n",
    "\n",
    "class PlannerTool(ToolDefinition[PlannerAction, PlannerObservation]):\n",
    "    \"\"\"Research planner tool definition\"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, conv_state, llm: LLM) -> List[ToolDefinition]:\n",
    "        executor = PlannerExecutor(llm)\n",
    "        return [\n",
    "            cls(\n",
    "                description=PLANNER_DESCRIPTION,\n",
    "                action_type=PlannerAction,\n",
    "                observation_type=PlannerObservation,\n",
    "                executor=executor,\n",
    "            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Research Synthesizer Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthesizer Tool - Combines research findings into coherent reports\n",
    "class SynthesizerAction(Action):\n",
    "    \"\"\"Action to synthesize research findings\"\"\"\n",
    "    topic: str = Field(description=\"Research topic\")\n",
    "    findings_file: str = Field(description=\"Path to file containing research findings\")\n",
    "    output_format: str = Field(\n",
    "        default=\"markdown\",\n",
    "        description=\"Output format: markdown or json\"\n",
    "    )\n",
    "\n",
    "class SynthesizerObservation(Observation):\n",
    "    \"\"\"Observation containing synthesized report\"\"\"\n",
    "    report: ResearchReport = Field(description=\"Synthesized research report\")\n",
    "    report_path: str = Field(description=\"Path to saved report file\")\n",
    "    \n",
    "    @property\n",
    "    def to_llm_content(self):\n",
    "        findings_summary = \"\\n\".join([\n",
    "            f\"  ‚Ä¢ {f.key_point} (confidence: {f.confidence:.2f})\"\n",
    "            for f in self.report.findings[:3]\n",
    "        ])\n",
    "        return [TextContent(text=f\"\"\"\n",
    "Research Report Synthesized:\n",
    "Topic: {self.report.topic}\n",
    "\n",
    "Executive Summary:\n",
    "{self.report.executive_summary[:200]}...\n",
    "\n",
    "Key Findings ({len(self.report.findings)} total):\n",
    "{findings_summary}\n",
    "\n",
    "Report saved to: {self.report_path}\n",
    "\"\"\")]\n",
    "\n",
    "class SynthesizerExecutor(ToolExecutor[SynthesizerAction, SynthesizerObservation]):\n",
    "    \"\"\"Executor that synthesizes research findings\"\"\"\n",
    "    \n",
    "    def __init__(self, llm: LLM, file_editor: FileEditorTool):\n",
    "        self.llm = llm\n",
    "        self.file_editor = file_editor\n",
    "    \n",
    "    def __call__(self, action: SynthesizerAction, conversation=None) -> SynthesizerObservation:\n",
    "        # Read findings from file\n",
    "        try:\n",
    "            with open(action.findings_file, 'r') as f:\n",
    "                findings_content = f.read()\n",
    "        except Exception as e:\n",
    "            findings_content = f\"Error reading findings: {e}\"\n",
    "        \n",
    "        # Use LLM to synthesize findings\n",
    "        prompt = f\"\"\"\n",
    "Synthesize the following research findings into a comprehensive report on \"{action.topic}\":\n",
    "\n",
    "{findings_content}\n",
    "\n",
    "Create a structured report with:\n",
    "1. Executive summary (2-3 paragraphs)\n",
    "2. Key findings with evidence and sources\n",
    "3. Research methodology\n",
    "4. Limitations\n",
    "5. Recommendations\n",
    "\n",
    "Output as JSON matching the ResearchReport structure.\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.llm.completion(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        # Parse response into report\n",
    "        try:\n",
    "            report_data = json.loads(response.choices[0].message.content)\n",
    "            report = ResearchReport(**report_data)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to parse report: {e}\")\n",
    "            # Create a basic report\n",
    "            report = ResearchReport(\n",
    "                topic=action.topic,\n",
    "                executive_summary=\"Research synthesis in progress...\",\n",
    "                findings=[],\n",
    "                methodology=\"Web search and content analysis\",\n",
    "                limitations=[\"Limited to available online sources\"],\n",
    "                recommendations=[\"Further research recommended\"]\n",
    "            )\n",
    "        \n",
    "        # Save report to file\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        report_filename = f\"research_report_{timestamp}.{action.output_format}\"\n",
    "        \n",
    "        if action.output_format == \"markdown\":\n",
    "            # Convert to markdown\n",
    "            markdown_content = f\"\"\"\n",
    "# Research Report: {report.topic}\n",
    "\n",
    "**Generated:** {report.created_at.strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "{report.executive_summary}\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "\"\"\"\n",
    "            for i, finding in enumerate(report.findings, 1):\n",
    "                markdown_content += f\"\"\"\n",
    "### Finding {i}: {finding.key_point}\n",
    "\n",
    "**Confidence:** {finding.confidence:.2f}\n",
    "\n",
    "**Evidence:**\n",
    "\"\"\"\n",
    "                for evidence in finding.evidence:\n",
    "                    markdown_content += f\"- {evidence}\\n\"\n",
    "                \n",
    "                markdown_content += \"\\n**Sources:**\\n\"\n",
    "                for source in finding.sources:\n",
    "                    markdown_content += f\"- [{source}]({source})\\n\"\n",
    "            \n",
    "            markdown_content += f\"\"\"\n",
    "\n",
    "## Methodology\n",
    "\n",
    "{report.methodology}\n",
    "\n",
    "## Limitations\n",
    "\n",
    "\"\"\"\n",
    "            for limitation in report.limitations:\n",
    "                markdown_content += f\"- {limitation}\\n\"\n",
    "            \n",
    "            markdown_content += \"\\n## Recommendations\\n\\n\"\n",
    "            for rec in report.recommendations:\n",
    "                markdown_content += f\"- {rec}\\n\"\n",
    "            \n",
    "            with open(report_filename, 'w') as f:\n",
    "                f.write(markdown_content)\n",
    "        else:\n",
    "            # Save as JSON\n",
    "            with open(report_filename, 'w') as f:\n",
    "                json.dump(report.model_dump(), f, indent=2, default=str)\n",
    "        \n",
    "        return SynthesizerObservation(report=report, report_path=report_filename)\n",
    "\n",
    "# Tool definition\n",
    "SYNTHESIZER_DESCRIPTION = \"\"\"\n",
    "Research synthesis tool that combines findings into structured reports.\n",
    "- Aggregates research findings with citations\n",
    "- Creates executive summaries\n",
    "- Identifies key insights and patterns\n",
    "- Outputs markdown or JSON reports\n",
    "\"\"\"\n",
    "\n",
    "class SynthesizerTool(ToolDefinition[SynthesizerAction, SynthesizerObservation]):\n",
    "    \"\"\"Research synthesizer tool definition\"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, conv_state, llm: LLM) -> List[ToolDefinition]:\n",
    "        # Create file editor for the executor\n",
    "        file_editor = FileEditorTool.create(conv_state)[0]\n",
    "        executor = SynthesizerExecutor(llm, file_editor)\n",
    "        return [\n",
    "            cls(\n",
    "                description=SYNTHESIZER_DESCRIPTION,\n",
    "                action_type=SynthesizerAction,\n",
    "                observation_type=SynthesizerObservation,\n",
    "                executor=executor,\n",
    "            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Web Search Tool (Tavily API)\n",
    "\n",
    "Custom tool for web search using Tavily API directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Search Tool using Tavily API\n",
    "from tavily import TavilyClient\n",
    "\n",
    "class SearchAction(Action):\n",
    "    \"\"\"Action to search the web\"\"\"\n",
    "    query: str = Field(description=\"Search query\")\n",
    "    search_depth: str = Field(\n",
    "        default=\"basic\",\n",
    "        description=\"Search depth: basic or advanced\"\n",
    "    )\n",
    "    max_results: int = Field(\n",
    "        default=5,\n",
    "        description=\"Maximum number of results to return\"\n",
    "    )\n",
    "\n",
    "class SearchObservation(Observation):\n",
    "    \"\"\"Observation containing search results\"\"\"\n",
    "    results: List[SearchResult] = Field(description=\"Search results\")\n",
    "    query: str = Field(description=\"Original search query\")\n",
    "    \n",
    "    @property\n",
    "    def to_llm_content(self):\n",
    "        if not self.results:\n",
    "            return [TextContent(text=f\"No results found for: {self.query}\")]\n",
    "        \n",
    "        results_text = f\"Search results for '{self.query}':\\n\\n\"\n",
    "        for i, result in enumerate(self.results[:5], 1):\n",
    "            results_text += f\"{i}. **{result.title}**\\n\"\n",
    "            results_text += f\"   URL: {result.url}\\n\"\n",
    "            results_text += f\"   {result.snippet[:200]}...\\n\\n\"\n",
    "        \n",
    "        return [TextContent(text=results_text)]\n",
    "\n",
    "class SearchExecutor(ToolExecutor[SearchAction, SearchObservation]):\n",
    "    \"\"\"Executor that performs web searches using Tavily\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        self.client = TavilyClient(api_key=api_key)\n",
    "    \n",
    "    def __call__(self, action: SearchAction, conversation=None) -> SearchObservation:\n",
    "        try:\n",
    "            # Perform search\n",
    "            response = self.client.search(\n",
    "                query=action.query,\n",
    "                search_depth=action.search_depth,\n",
    "                max_results=action.max_results\n",
    "            )\n",
    "            \n",
    "            # Convert to our SearchResult format\n",
    "            results = []\n",
    "            for item in response.get('results', []):\n",
    "                result = SearchResult(\n",
    "                    title=item.get('title', 'No title'),\n",
    "                    url=item.get('url', ''),\n",
    "                    snippet=item.get('content', '')[:500],  # Limit snippet length\n",
    "                    relevance_score=item.get('score', 0.0)\n",
    "                )\n",
    "                results.append(result)\n",
    "            \n",
    "            return SearchObservation(results=results, query=action.query)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Search failed: {e}\")\n",
    "            return SearchObservation(results=[], query=action.query)\n",
    "\n",
    "# Tool definition\n",
    "SEARCH_DESCRIPTION = \"\"\"\n",
    "Web search tool powered by Tavily API.\n",
    "- Searches the web for current information\n",
    "- Returns structured results with titles, URLs, and snippets\n",
    "- Supports basic and advanced search depths\n",
    "- Use for finding recent information, research papers, news, etc.\n",
    "\"\"\"\n",
    "\n",
    "class SearchTool(ToolDefinition[SearchAction, SearchObservation]):\n",
    "    \"\"\"Web search tool definition\"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, conv_state, api_key: str) -> List[ToolDefinition]:\n",
    "        executor = SearchExecutor(api_key)\n",
    "        return [\n",
    "            cls(\n",
    "                description=SEARCH_DESCRIPTION,\n",
    "                action_type=SearchAction,\n",
    "                observation_type=SearchObservation,\n",
    "                executor=executor,\n",
    "            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Research Agent\n",
    "\n",
    "Now let's create our deep research agent with all the tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = LLM(\n",
    "    model=os.environ[\"LLM_MODEL\"],\n",
    "    api_key=SecretStr(os.environ[\"LLM_API_KEY\"]),\n",
    "    base_url=os.environ.get(\"LLM_BASE_URL\"),\n",
    "    usage_id=\"research-agent\"\n",
    ")\n",
    "\n",
    "# Register custom tools\n",
    "def create_research_tools(conv_state) -> List[ToolDefinition]:\n",
    "    \"\"\"Factory function to create research tools\"\"\"\n",
    "    tools = []\n",
    "    \n",
    "    # Add planner tool\n",
    "    tools.extend(PlannerTool.create(conv_state, llm))\n",
    "    \n",
    "    # Add synthesizer tool\n",
    "    tools.extend(SynthesizerTool.create(conv_state, llm))\n",
    "    \n",
    "    # Add search tool\n",
    "    tavily_api_key = os.environ.get(\"TAVILY_API_KEY\")\n",
    "    if tavily_api_key:\n",
    "        tools.extend(SearchTool.create(conv_state, tavily_api_key))\n",
    "    else:\n",
    "        logger.warning(\"TAVILY_API_KEY not set, search tool will not be available\")\n",
    "    \n",
    "    return tools\n",
    "\n",
    "register_tool(\"ResearchTools\", create_research_tools)\n",
    "\n",
    "# Create agent with all tools\n",
    "tools = [\n",
    "    Tool(name=TerminalTool.name),\n",
    "    Tool(name=FileEditorTool.name),\n",
    "    Tool(name=TaskTrackerTool.name),\n",
    "    Tool(name=\"ResearchTools\"),\n",
    "]\n",
    "\n",
    "agent = Agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "print(\"Research agent created with tools:\")\n",
    "for tool in tools:\n",
    "    print(f\"  - {tool.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Orchestration Loop\n",
    "\n",
    "The main controller that orchestrates the research workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchOrchestrator:\n",
    "    \"\"\"Orchestrates the deep research workflow\"\"\"\n",
    "    \n",
    "    def __init__(self, agent: Agent, workspace: str):\n",
    "        self.agent = agent\n",
    "        self.workspace = workspace\n",
    "        self.conversation = None\n",
    "        self.research_state = {\n",
    "            \"plan\": None,\n",
    "            \"findings\": [],\n",
    "            \"report\": None\n",
    "        }\n",
    "    \n",
    "    def research(self, topic: str, depth: str = \"moderate\"):\n",
    "        \"\"\"Execute the complete research workflow\"\"\"\n",
    "        print(f\"\\nüî¨ Starting deep research on: {topic}\")\n",
    "        print(f\"   Research depth: {depth}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Create conversation\n",
    "        self.conversation = Conversation(\n",
    "            agent=self.agent,\n",
    "            workspace=self.workspace\n",
    "        )\n",
    "        \n",
    "        # Phase 1: Planning\n",
    "        print(\"\\nüìã Phase 1: Research Planning\")\n",
    "        planning_prompt = f\"\"\"\n",
    "I need to conduct {depth} research on the topic: \"{topic}\"\n",
    "\n",
    "Please:\n",
    "1. Use the research planner tool to create a detailed research plan\n",
    "2. Use the task tracker to organize the research tasks\n",
    "3. Identify the top 3 priority tasks to start with\n",
    "\"\"\"\n",
    "        self.conversation.send_message(planning_prompt)\n",
    "        self.conversation.run()\n",
    "        \n",
    "        # Phase 2: Research Execution\n",
    "        print(\"\\nüîç Phase 2: Research Execution\")\n",
    "        research_prompt = f\"\"\"\n",
    "Now let's execute the research plan:\n",
    "\n",
    "1. For each high-priority task, use the web search tool to find relevant information\n",
    "2. Save the search results and key findings to a file called 'research_findings.json'\n",
    "3. Organize findings by subtopic with proper citations\n",
    "4. Update the task tracker as you complete each task\n",
    "\n",
    "Focus on finding:\n",
    "- Current state and recent developments\n",
    "- Key concepts and definitions\n",
    "- Expert opinions and analysis\n",
    "- Relevant statistics and data\n",
    "\"\"\"\n",
    "        self.conversation.send_message(research_prompt)\n",
    "        self.conversation.run()\n",
    "        \n",
    "        # Phase 3: Synthesis\n",
    "        print(\"\\nüìù Phase 3: Synthesis and Report Generation\")\n",
    "        synthesis_prompt = f\"\"\"\n",
    "Now synthesize all the research findings:\n",
    "\n",
    "1. Use the synthesizer tool to create a comprehensive research report\n",
    "2. Input file: 'research_findings.json'\n",
    "3. Output format: markdown\n",
    "4. Ensure the report includes:\n",
    "   - Executive summary\n",
    "   - Key findings with evidence\n",
    "   - Proper citations\n",
    "   - Limitations and recommendations\n",
    "\n",
    "After creating the report, provide a brief summary of the key insights.\n",
    "\"\"\"\n",
    "        self.conversation.send_message(synthesis_prompt)\n",
    "        self.conversation.run()\n",
    "        \n",
    "        print(\"\\n‚úÖ Research completed!\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Get metrics\n",
    "        metrics = self.conversation.conversation_stats.get_combined_metrics()\n",
    "        print(f\"\\nüìä Research Metrics:\")\n",
    "        print(f\"   Total tokens: {metrics.total_tokens:,}\")\n",
    "        print(f\"   Total cost: ${metrics.accumulated_cost:.4f}\")\n",
    "        print(f\"   LLM calls: {metrics.llm_calls}\")\n",
    "        print(f\"   Tool calls: {metrics.tool_calls}\")\n",
    "        \n",
    "        return self.conversation\n",
    "\n",
    "# Create orchestrator\n",
    "orchestrator = ResearchOrchestrator(agent, os.getcwd())\n",
    "print(\"Research orchestrator ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Research a Topic\n",
    "\n",
    "Let's demonstrate the deep research agent in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example research topic\n",
    "research_topic = \"The impact of large language models on software development practices\"\n",
    "\n",
    "# Run the research\n",
    "conversation = orchestrator.research(\n",
    "    topic=research_topic,\n",
    "    depth=\"moderate\"  # Options: quick, moderate, deep\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Research Report\n",
    "\n",
    "Let's check the generated research report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and display the generated report\n",
    "import glob\n",
    "\n",
    "# Find the most recent research report\n",
    "report_files = glob.glob(\"research_report_*.md\")\n",
    "if report_files:\n",
    "    latest_report = max(report_files, key=os.path.getctime)\n",
    "    print(f\"Found report: {latest_report}\\n\")\n",
    "    \n",
    "    # Display first 1000 characters\n",
    "    with open(latest_report, 'r') as f:\n",
    "        content = f.read()\n",
    "        print(content[:1000] + \"...\\n\\n[Report truncated for display]\")\n",
    "else:\n",
    "    print(\"No research report found. The synthesis may have encountered an issue.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Research Session\n",
    "\n",
    "You can also interact with the research agent directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new conversation for interactive research\n",
    "interactive_conversation = Conversation(\n",
    "    agent=agent,\n",
    "    workspace=os.getcwd()\n",
    ")\n",
    "\n",
    "# Send a custom research request\n",
    "custom_request = \"\"\"\n",
    "I need to research \"quantum computing applications in cryptography\".\n",
    "Please create a research plan and find the latest developments in this field.\n",
    "Focus on practical applications and recent breakthroughs.\n",
    "\"\"\"\n",
    "\n",
    "interactive_conversation.send_message(custom_request)\n",
    "interactive_conversation.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Architectural Patterns Demonstrated\n",
    "\n",
    "This notebook showcases several state-of-the-art patterns for deep agents:\n",
    "\n",
    "### 1. **Task Decomposition**\n",
    "- The `PlannerTool` breaks down complex research topics into structured, prioritized tasks\n",
    "- Tasks have dependencies and clear objectives\n",
    "- Uses Pydantic models for type safety\n",
    "\n",
    "### 2. **Tool Integration**\n",
    "- Custom tools (Planner, Synthesizer, Search) for specialized tasks\n",
    "- Direct API integration for web search via Tavily\n",
    "- Built-in tools for file operations and task tracking\n",
    "\n",
    "### 3. **Structured Outputs**\n",
    "- All data structures use Pydantic models\n",
    "- Validated inputs and outputs\n",
    "- JSON and Markdown report generation\n",
    "\n",
    "### 4. **Orchestration Pattern**\n",
    "- Clear phases: Planning ‚Üí Research ‚Üí Synthesis\n",
    "- State tracking throughout the workflow\n",
    "- Metrics collection for performance monitoring\n",
    "\n",
    "### 5. **LLM-Powered Synthesis**\n",
    "- Uses LLM for intelligent content aggregation\n",
    "- Maintains citations and evidence chains\n",
    "- Generates executive summaries\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "To extend this basic implementation:\n",
    "\n",
    "1. **Add Sub-agent Delegation**: Create specialized sub-agents for different research domains\n",
    "2. **Implement Persistence**: Save conversation state and research progress\n",
    "3. **Add Iterative Refinement**: Allow the agent to refine its research based on initial findings\n",
    "4. **Enhanced Error Handling**: Add retry logic and fallback strategies\n",
    "5. **Multi-source Integration**: Add more MCP servers for diverse data sources\n",
    "\n",
    "See the advanced notebook (`02_advanced_deep_research.ipynb`) for these features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Clean up generated files\n",
    "# import os\n",
    "# for f in glob.glob(\"research_report_*.md\") + glob.glob(\"research_findings.json\"):\n",
    "#     os.remove(f)\n",
    "#     print(f\"Removed: {f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}